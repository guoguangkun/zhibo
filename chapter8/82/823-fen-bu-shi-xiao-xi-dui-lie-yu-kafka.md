##4.3.3 分布式消息队列与Kafka  
kafka基本原理
简介
Kafka是由Linkedin开发的消息队列，使用Scala语言编写。
分布式、多分区、多副本、基于发布/订阅的消息系统
按topic存储，为了提高吞吐率，每个topic分成多个分区，每个分区可以有副本。生产者将消息发布到kafka中，消费者订阅主题。
Kafka设计的初衷是希望作为一个统一的信息收集平台，能够实时的收集反馈信息，并能够支撑较大的数据量，且具备良好的容错能力。

特性
消息持久化：采用时间复杂度O(1)的磁盘结构顺序存储
高吞吐量：支持每秒百万级别的消息
易扩展：新增机器，集群无需停机，自动感知
高容错：通过多分区，多副本的冗余存储提供高容错性
多客户端支持：JAVA\PHP\PYTHON等
实时性：进入到kafka的消息能够立刻被消费者消费

消息队列的作用
消息的临时存储区域、提供数据的缓冲，保证系统的稳定性
应用程序解耦并行处理。传统的消息处理是采用串行的方式，
顺序保证 一个topic内不一定有序，分区内是有序的。
高吞吐率
高容错、高可用
可扩展
峰值处理


原理图
在kafka中，发送消息者称为Producer，而消息拉取者称为Consumer。通常，consumer是被定义在Consumer Group里
kafka通过Zookeeper管理集群。同一个消息可以被多个Consumer Group拉取处理，但是在一个Consumer Group里只能有一个Consumer处理该条消息。Consumer之间是竞争互斥的关系。
kafka集群由多个实例组成，每个节点称为Broker，对消息保存时根据Topic进行归类。
一个Topic可以被划分为多个Partition。每个Partition可以有多个副本。同一个partition的不同副本分布到不同的broker。
图
每一组partition有一个leaer，其余为follower。leader负责读写数据，follower只负责与leader同步数据。

Partition内消息顺序存储，写入新消息采用追加的方式，消费消息采用FIFO的方式顺序拉取消息。
一个Topic可以有多个分区，Kafka只保证同一个分区内有序，不保证Topic整体（多个分区之间）有序。
图

Consumer Group（CG），为了加快读取速度，多个consumer可以划分为一个组，并行消费一个Topic。一个Topic可以由多个CG订阅，多个CG之间是平等的，同一个CG内可以有一个或多个consumer，同一个CG内的consumer之间是竞争关系，一个消息在一个CG内只能被一个consumer消费。

一个CG内的consumer对消息的处理逻辑是相同的，不同的CG的consumer对消息的处理逻辑不同。

kafka核心概念：
Broker：启动kafka的一个实例就是一个broker，一个kafka集群可以启动多个broker
Topic：kafka中同一种类型数据集的名称，相当于数据库中的表，producer将同一类型的数据写入同一个topic下，consumer从同一topic消费同一类型的数据
Partition：一个topic可以设置多个分区，相当于把一个数据集分成多份分别放到不同的分区中存储，一个topic可以有一个或者多个分区，分区内消息有序。
Replication：副本，一个partition可以设置一个或者多个副本，副本主要保证系统能够持续不丢失的对外提供服务，提高系统的容错能力。在0.8以前是没有Replication的，一旦某台broker宕机，其上partition数据便丢失。
Producer：消息生产者，负责向kafka中发布消息
Consumer Group：消费者所属组，一个CG可以包含一个或多个consumer，当一个topic被一个CG消费的时候，CG内只能有一个consumer消费同一条消息，不会出现同一个CG多个consumer同时消费一条消息造成一个消息被一个CG消费多次的情况。
Consumer：消息消费者，consumer从kafka指定的主题中拉取消息
Zookeeper：Zookeeper在kafka集群中主要用于协调管理，kafka将元数据信息保存在Zookeeper中，通过Zookeeper管理维护整个kafka集群的动态扩展、各个Broker负载均衡、Partition Leader选举等。

kafka存储
每个partition的副本是一个目录
Segment：段文件，kafka中最小数据存储单位，一个partition包含多个segment文件，每个segment以message在partition中的起始偏移量命名，以log结尾。
offset：消息在分区中的偏移量，用来在分区中唯一的标识这个消息
图

索引文件
kafka为了提高写入、查询速度，在partition文件夹下每一个segment log文件都有相同的索引文件，在kafka0.10以后的版本中会存在两个索引文件。一个用offset做名字以index结尾的索引文件，我们称为偏移量索引文件。一个是以消息写入的时间戳作为名字以timeindex结尾的索引文件，我们称为时间戳索引文件，如图。
图

偏移量索引文件：
以偏移量作为名称，index为后缀
索引内容格式：offset，position（物理存储位置）
采用稀疏存储方式
通过log.index.interval.bytes设置索引跨度
图

时间戳索引文件：
以时间戳作为名称，以timeindex为后缀。时间戳是由producer来决定，有两种时间，一种是消息创建时间的时间戳，一种是消息写入队列时间的时间戳。
索引内容格式：timestamp，offset
采用稀疏存储方式
通过log.index.interval.bytes设置索引跨度




kafka集群部署