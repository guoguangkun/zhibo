## 本章小结

本章介绍了iOS实现视频直播的整个过程和实现方式，在实现过程中用到了3个开源框架：GPUImage、LFLiveKit和IJKplayer。这些框架对初学者和快速开发者有很大帮助，当然如果想要自己实现直播也是可以的，实现过程相对复杂。

最后，介绍下和直播相关的一些内容，如下：

* 采集数据：iOS平台上采集音视频数据，需要使用AVFoundation.Framework框架，从captureSession会话的回调中获取音频，视频数据。
* 传输层协议：主要采用RTMP协议（默认端口1935，采用TCP协议）和HLS协议。
* 音/视频编码解码：FFMpege编码解码。
* 视频编码格式：H.265、H.264、MPEG-4等，封装容器有TS、MKV、AVI、MP4等。
* 音频编码格式：G.711μ、AAC、Opus等，封装有MP3、OGG、AAC等。
* 渲染工具：采用OpenGL渲染YUV数据，呈现视频画面。将PCM送入设备的硬件资源播放，产生声音。iOS播放流式音频，使用Audio Queue 的方式，即利用AudioToolbox.Framework 框架。



